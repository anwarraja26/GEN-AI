{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0Sku7ePeHz4"
      },
      "outputs": [],
      "source": [
        "print(\"hello world\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDIIh3wYeOGO"
      },
      "outputs": [],
      "source": [
        "!pip -q install chromadb openai langchain tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aa4V5VQFesRA"
      },
      "outputs": [],
      "source": [
        "!pip show chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YYlopoAezXC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7dQRySif-Op"
      },
      "outputs": [],
      "source": [
        "!wget -q https://www.dropbox.com/s/vs6ocyvpzzncvwh/new_articles.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFzde2CTft-6",
        "outputId": "ca3fc9a1-5529-45ea-b604-27d54592471a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "replace new_articles/05-07-fintech-space-continues-to-be-competitive-and-drama-filled.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!unzip -q new_articles.zip -d new_articles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ES4WezvAf_ll"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY']=\"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOPMy0JFirA6"
      },
      "outputs": [],
      "source": [
        "!pip install langchain -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8T6YsK1izv5"
      },
      "outputs": [],
      "source": [
        "!pip install langchain_community -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8u1O9zp_h4Ly"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66i6kgROinTP"
      },
      "outputs": [],
      "source": [
        "loader=DirectoryLoader(\"/content/new_articles\",glob=\"./*.txt\",loader_cls=TextLoader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykwsVB46j-BS"
      },
      "outputs": [],
      "source": [
        "document=loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Wdy1OpFkULv"
      },
      "outputs": [],
      "source": [
        "document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6V8B3Nk8kWcC"
      },
      "outputs": [],
      "source": [
        "# Split into chunks for that we are using the text-splitter\n",
        "# Recursive character TetSplitter it chunk size and chunk overlap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1G2y0KLqvD4"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
        "text=text_splitter.split_documents(document)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQKE973lrDPO"
      },
      "outputs": [],
      "source": [
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3EhRgnprL9i"
      },
      "outputs": [],
      "source": [
        "len(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUnJZ2U3rbpg"
      },
      "outputs": [],
      "source": [
        "text[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTliBJB_rcvo"
      },
      "outputs": [],
      "source": [
        "text[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIUu0aQDreK1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVJwYYTfrgsB"
      },
      "source": [
        "# Creating DB object"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LW_-0DnCwSxQ"
      },
      "source": [
        "## The below is using the open ai embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDQ5c9acrizq"
      },
      "outputs": [],
      "source": [
        "\n",
        "# from langchain import embeddings\n",
        "# persis_directory=\"db\"\n",
        "# embedding=OpenAIEmbeddings()\n",
        "# vectordb=Chroma.from_documents(documents=text,\n",
        "#                                embedding=embedding,\n",
        "#                                persist_directory=persis_directory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGhhjjD6waAx"
      },
      "source": [
        "## For that we are going to use hugging face embeding model\n",
        "## https://docs.trychroma.com/integrations/embedding-models/hugging-face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjpjS3ZmwInu"
      },
      "outputs": [],
      "source": [
        "# the below is from the documentation it is compleetely from chromadb\n",
        "\n",
        "\n",
        "# import chromadb.utils.embedding_functions as embedding_functions\n",
        "# huggingface_ef = embedding_functions.HuggingFaceEmbeddingFunction(\n",
        "#     api_key=\"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\",\n",
        "#     model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3H9xfUPzFsO"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "huggingface_ef = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pu5yW2Wlx1ZQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "persist_directory=\"db\"\n",
        "vectordb=Chroma.from_documents(documents=text,\n",
        "                               embedding=huggingface_ef,\n",
        "                               persist_directory=persist_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARl-0cEhx_PN"
      },
      "outputs": [],
      "source": [
        "vectordb.persist()\n",
        "vectordb=None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJQVoD76zkvo"
      },
      "outputs": [],
      "source": [
        "vectordb=Chroma(persist_directory=persist_directory,\n",
        "                embedding_function=huggingface_ef)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwrsRZ5bz_Jc"
      },
      "source": [
        "# Make a retriever for similarity equation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgn_02WAz7Fd"
      },
      "outputs": [],
      "source": [
        "retriever=vectordb.as_retriever()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJFZTaxu0If5"
      },
      "outputs": [],
      "source": [
        "docs=retriever.get_relevant_documents(\"How much money did microsoft raise\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aX9dYeFG0NMr"
      },
      "outputs": [],
      "source": [
        "len(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fi8B0d_w0VvZ"
      },
      "outputs": [],
      "source": [
        "# we can also specify how many we want\n",
        "retriever=vectordb.as_retriever(search_kwargs={\"k\":2})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSwrRX2E0l4m"
      },
      "outputs": [],
      "source": [
        "retriever.search_type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BYV9LqX0nvj"
      },
      "outputs": [],
      "source": [
        "docs=retriever.get_relevant_documents(\"How much money did microsoft raise\")\n",
        "len(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vm4emOU07fj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBHrRT8LU505"
      },
      "source": [
        "# MAKE A CHAIN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rfNhsTEVwCo"
      },
      "outputs": [],
      "source": [
        "# llm=OpenAI() # we dont have the open ai api so we go with the groq api\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EEKgkDpyU8X2"
      },
      "outputs": [],
      "source": [
        "!pip install langchain_groq -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SH__QDgbVXox"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(model_name=\"llama3-8b-8192\",api_key=\"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\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_oDAJXwVuUJ"
      },
      "outputs": [],
      "source": [
        "# Create the chain to answer question\n",
        "from langchain.chains import RetrievalQA\n",
        "qa_chain=RetrievalQA.from_chain_type(llm=llm,\n",
        "                                     chain_type=\"stuff\",\n",
        "                                     retriever=retriever,\n",
        "                                     return_source_documents=True\n",
        "                                     )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZcoWQfTYLYN"
      },
      "outputs": [],
      "source": [
        "def process_llm_response(llm_response):\n",
        "  print(llm_response['result'])\n",
        "  print('\\nSources:')\n",
        "  for source in llm_response['source_documents']:\n",
        "    print(source.metadata['source'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvPGgQicWwZr"
      },
      "outputs": [],
      "source": [
        "query=\"How much money did Microsoft raise?\"\n",
        "llm_response=qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Niq3doDkWU4Y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQf8EzdqYn_8"
      },
      "source": [
        "# Deleting the DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvLt3EzRYph0"
      },
      "outputs": [],
      "source": [
        "!zip -r db.zip ./db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZ-Nz7M1YuJI"
      },
      "outputs": [],
      "source": [
        "vectordb.delete_collection()\n",
        "vectordb.persist()\n",
        "\n",
        "!rm -rf db/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BW-DEPD9Y2OB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}